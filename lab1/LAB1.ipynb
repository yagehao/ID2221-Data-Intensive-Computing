{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/osboxes/lab1/pagecounts-20160101-000000_parsed.out MapPartitionsRDD[1] at textFile at <console>:29"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@5ee3f9b6\n",
       "pagecounts = /home/osboxes/lab1/pagecounts-20160101-000000_parsed.out MapPartitionsRDD[1] at textFile at <console>:29\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "3324129"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark= SparkSession.builder().getOrCreate()\n",
    "import org.apache.spark.rdd.RDD\n",
    "val pagecounts = sc.textFile(\"/home/osboxes/lab1/pagecounts-20160101-000000_parsed.out\")\n",
    "print(pagecounts)\n",
    "pagecounts.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, convert the pagecounts from RDD[String] into RDD[Log]:\n",
    "\n",
    "1 Create a case class called Log using the four ﬁeld names of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Log\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "case class Log(code: String, title:String, hits:Int, size:Long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Create a function that takes a string, split it by white space and converts it into a log object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Log_obj: (s: String)Log\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "def Log_obj(s: String) : Log ={\n",
    "    val splits = s.split(\" \")\n",
    "    return Log(splits(0).toString,splits(1).toString,splits(2).toInt,splits(3).toLong)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Create a function that takes an RDD[String] and returns an RDD[Log]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RDD_Log: (s: org.apache.spark.rdd.RDD[String])org.apache.spark.rdd.RDD[Log]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "def RDD_Log(s: RDD[String]) : RDD[Log] = {\n",
    "    return s.map(x=>Log_obj(x))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd_page = MapPartitionsRDD[2] at map at <console>:31\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[2] at map at <console>:31"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd_page = RDD_Log(pagecounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Retrieve the ﬁrst 15 records and print out the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log(aa,271_a.C,1,4675)\n",
      "Log(aa,Category:User_th,1,4770)\n",
      "Log(aa,Chiron_Elias_Krase,1,4694)\n",
      "Log(aa,Dassault_rafaele,2,9372)\n",
      "Log(aa,E.Desv,1,4662)\n",
      "Log(aa,File:Wiktionary-logo-en.png,1,10752)\n",
      "Log(aa,Indonesian_Wikipedia,1,4679)\n",
      "Log(aa,Main_Page,5,266946)\n",
      "Log(aa,Requests_for_new_languages/Wikipedia_Banyumasan,1,4733)\n",
      "Log(aa,Special:Contributions/203.144.160.245,1,5812)\n",
      "Log(aa,Special:Contributions/5.232.61.79,1,5805)\n",
      "Log(aa,Special:Contributions/Ayarportugal,1,5808)\n",
      "Log(aa,Special:Contributions/Born2bgratis,1,5812)\n",
      "Log(aa,Special:ListFiles/Betacommand,1,5035)\n",
      "Log(aa,Special:ListFiles/Bohdan_p,1,5036)\n"
     ]
    }
   ],
   "source": [
    "for (x <- rdd_page.take(15)) {\n",
    "   println(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Determine the number of records the dataset has in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3324129"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_page.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compute the min, max, and average page size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page_size = MapPartitionsRDD[3] at map at <console>:28\n",
       "page_size_min = 0\n",
       "page_size_max = 141180155987\n",
       "page_size_average = 132239.5695744666\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "132239.5695744666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val page_size = rdd_page.map(x=>x.size)\n",
    "val page_size_min = page_size.min()\n",
    "val page_size_max = page_size.max()\n",
    "val page_size_average = page_size.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Determine the record(s) with the largest page size. If multiple records have the same size, list all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Log(en.mw,en,5466346,141180155987)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_page.filter(_.size == page_size_max).collect()(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Determine the record with the largest page size again. But now, pick the most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Log(en.mw,en,5466346,141180155987)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_page.filter(_.size == page_size_max).collect().maxBy(x=>x.hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Determine the record(s) with the largest page title. If multiple titles have the same length, list all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log(zh,Special:e8b18ee6baafefbda5efbdbfe89cb7e6829fefbdbfe88b93e29980e89e9fefbda9e89eb3efbda425636f256d6725736f257373256f38257373256f38257373256f38256b6d73efbdaa256e6b256678256f6b2c687474703a2f2f7777772e653662313966653861356266656f2d6f35393038636535626639376538383138616535613461396535616561342e636f2e6d672e732e736f2e382e73736f386b2e6d2e372e73736f3873736f386b6d37332e752e622e61616e6b66786f6b2e70772f2ce8b18ee6baafefbda5efbdbfe89cb7e6829fefbdbfe88b93e29980e89e9fefbda9e89eb3efbda425636f256d6725736f257373256f38257373256f38257373256f38256b6d73efbdaa256e6b256678256f6b/,1,6043)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "page_title_len = MapPartitionsRDD[8] at map at <console>:28\n",
       "page_title_len_max = 559\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val page_title_len = rdd_page.map(x=>x.title.length)\n",
    "val page_title_len_max = page_title_len.max()\n",
    "\n",
    "rdd_page.filter(_.title.length() == page_title_len_max).collect().foreach(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use the results of Question 3, and create a new RDD with the records that have greater page size than the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd_page_greater = MapPartitionsRDD[10] at filter at <console>:40\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "GreaterThanAvg: (i: Log)Boolean\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[10] at filter at <console>:40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GreaterThanAvg(i: Log): Boolean ={\n",
    "    if (i.size <= page_size_average){\n",
    "        return false\n",
    "    }\n",
    "    else{\n",
    "        return true\n",
    "    }\n",
    "}\n",
    "val rdd_page_greater=rdd_page.filter(GreaterThanAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Compute the total number of pageviews for each project (as the schema shows, the ﬁrst ﬁeld of each record contains the project code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pageview = ShuffledRDD[12] at reduceByKey at <console>:28\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "ShuffledRDD[12] at reduceByKey at <console>:28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pageview = rdd_page.map(x=>(x.code, x.hits)).reduceByKey(_ + _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Report the 10 most popular pageviews of all projects, sorted by the total number of hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(en.mw,5466346)\n",
      "(en,4959090)\n",
      "(es.mw,695531)\n",
      "(ja.mw,611443)\n",
      "(de.mw,572119)\n",
      "(fr.mw,536978)\n",
      "(ru.mw,466742)\n",
      "(it.mw,400297)\n",
      "(de,315929)\n",
      "(commons.m,285796)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "top10 = Array((5466346,en.mw), (4959090,en), (695531,es.mw), (611443,ja.mw), (572119,de.mw), (536978,fr.mw), (466742,ru.mw), (400297,it.mw), (315929,de), (285796,commons.m))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array((5466346,en.mw), (4959090,en), (695531,es.mw), (611443,ja.mw), (572119,de.mw), (536978,fr.mw), (466742,ru.mw), (400297,it.mw), (315929,de), (285796,commons.m))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val top10 = pageview.map(x=>(x._2, x._1)).sortByKey().top(10)\n",
    "top10.map(x=>(x._2,x._1)).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Determine the number of page titles that start with the article “The”. How many of those page titles are not part of the English project (Pages that are part of the English project have “en” as the ﬁrst ﬁeld)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pagesEN = 9128\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "9128"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pagesEN = rdd_page.filter(x => (!x.code.startsWith(\"en\") && x.title.startsWith(\"The\"))).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Determine the percentage of pages that have only received a single page view in this one hour of log data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onepageview = 2558332.0\n",
       "totalpage = 3324129.0\n",
       "percentage = 0.76962477\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "0.76962477"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val onepageview = rdd_page.filter(x => (x.hits == 1)).count().toFloat\n",
    "val totalpage = rdd_page.count().toFloat\n",
    "val percentage = onepageview/totalpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Determine the number of unique terms appearing in the page titles. Note that in page titles, terms are delimited by “ ” instead of a white space. You can use any number of normalization steps (e.g., lowercasing, removal of non-alphanumeric characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "terms = MapPartitionsRDD[23] at filter at <console>:28\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[23] at filter at <console>:28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val terms = rdd_page.map(x=>x.title.toLowerCase).flatMap(x=>x.split(\"_\")).map(_.replaceAll(\"[^A-Za-z0-9]\", \"\")).filter(x => x.length >0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distinct_terms = 1688528\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "1688528"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val distinct_terms = terms.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "13. Determine the most frequently occurring page title term in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res = Array((194407,of))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array((194407,of))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val res = terms.map(x=>(x,1)).reduceByKey(_ + _).map(x=>(x._2, x._1)).sortByKey().top(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((194407,of))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.filter(x=>x._2 == \"of\").take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 -Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [code: string, title: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[code: string, title: string ... 2 more fields]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = rdd_page.toDF(\"code\",\"title\",\"hits\",\"size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----+------+\n",
      "|code|               title|hits|  size|\n",
      "+----+--------------------+----+------+\n",
      "|  aa|             271_a.C|   1|  4675|\n",
      "|  aa|    Category:User_th|   1|  4770|\n",
      "|  aa|  Chiron_Elias_Krase|   1|  4694|\n",
      "|  aa|    Dassault_rafaele|   2|  9372|\n",
      "|  aa|              E.Desv|   1|  4662|\n",
      "|  aa|File:Wiktionary-l...|   1| 10752|\n",
      "|  aa|Indonesian_Wikipedia|   1|  4679|\n",
      "|  aa|           Main_Page|   5|266946|\n",
      "|  aa|Requests_for_new_...|   1|  4733|\n",
      "|  aa|Special:Contribut...|   1|  5812|\n",
      "|  aa|Special:Contribut...|   1|  5805|\n",
      "|  aa|Special:Contribut...|   1|  5808|\n",
      "|  aa|Special:Contribut...|   1|  5812|\n",
      "|  aa|Special:ListFiles...|   1|  5035|\n",
      "|  aa|Special:ListFiles...|   1|  5036|\n",
      "|  aa|Special:ListFiles...|   1|  5032|\n",
      "|  aa|Special:Log/Md._F...|   1|  5529|\n",
      "|  aa|Special:Log/MikeL...|   1|  5368|\n",
      "|  aa|Special:MyLanguag...|   1|  4701|\n",
      "|  aa|Special:RecentCha...|   1|  6152|\n",
      "+----+--------------------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compute the min, max, and average page size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sizemax = 141180155987\n",
       "sizemin = 0\n",
       "sizemean = 132239.56957446598\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "132239.56957446598"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import SparkSession._\n",
    "\n",
    "val sizemax = df.agg(max(col(\"size\"))).collect()(0)(0)\n",
    "val sizemin = df.agg(min(col(\"size\"))).collect()(0)(0)\n",
    "val sizemean = df.agg(mean(col(\"size\"))).collect()(0)(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Determine the record with the largest page size again. But now, pick the most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+------------+\n",
      "| code|title|   hits|        size|\n",
      "+-----+-----+-------+------------+\n",
      "|en.mw|   en|5466346|141180155987|\n",
      "+-----+-----+-------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df_sizemax = [code: string, title: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[code: string, title: string ... 2 more fields]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_sizemax = df.filter(df(\"size\") === sizemax)\n",
    "df_sizemax.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ordered = org.apache.spark.sql.expressions.WindowSpec@7ab5bc71\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.expressions.WindowSpec@7ab5bc71"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ordered = Window.orderBy(df_sizemax.col(\"hits\").desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+------------+----+\n",
      "| code|title|   hits|        size|rank|\n",
      "+-----+-----+-------+------------+----+\n",
      "|en.mw|   en|5466346|141180155987|   1|\n",
      "+-----+-----+-------+------------+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ranked = [code: string, title: string ... 3 more fields]\n",
       "maxDf = [code: string, title: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[code: string, title: string ... 3 more fields]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ranked = df_sizemax.withColumn(\"rank\", dense_rank.over(ordered))\n",
    "val maxDf = ranked.filter(\"rank == 1\")\n",
    "maxDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use the results of Question 3, and create a new RDD with the records that have greater page size than the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+------+\n",
      "|  code|               title|hits|  size|\n",
      "+------+--------------------+----+------+\n",
      "|    aa|           Main_Page|   5|266946|\n",
      "|ace.mw|                 ace|  31|827168|\n",
      "|    af|                1859|   4|219540|\n",
      "|    af|          18_Oktober|   4|264724|\n",
      "|    af|                1941|   4|256344|\n",
      "|    af|                2016|   5|215498|\n",
      "|    af|          4_Januarie|   4|268828|\n",
      "|    af|         Afrika-unie|   1|172078|\n",
      "|    af|             Big_Ben|  13|136201|\n",
      "|    af|    Comrades-maraton|   1|155180|\n",
      "|    af|     Dmitri_Medwedef|   2|141328|\n",
      "|    af|               Elsas|   4|319408|\n",
      "|    af|              Engels|   2|182375|\n",
      "|    af|         Erich_Fromm|   4|215612|\n",
      "|    af|            Filosoof|   2|134400|\n",
      "|    af|                GNTA|  77|511277|\n",
      "|    af|Gebruiker:Aliwal2012|   2|359320|\n",
      "|    af|      Gebruiker:JCIV|   2|268216|\n",
      "|    af|     Gebruiker:Morne|   3|991701|\n",
      "|    af|   Gebruiker:Naudefj|   3|730849|\n",
      "+------+--------------------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df_greater = [code: string, title: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[code: string, title: string ... 2 more fields]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_greater=df.filter(df(\"size\") > sizemean)\n",
    "df_greater.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Determine the number of unique terms appearing in the page titles. Note that in page titles, terms are delimited by “ ” instead of a white space. You can use any number of normalization steps (e.g., lowercasing, removal of non-alphanumeric characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df1 = [col: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[col: string]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df1 = df.select(explode(split(lower(col(\"title\")),\"_\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_term = [col: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[col: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_term = df1.withColumn(\"col\",regexp_replace($\"col\", \"[^A-Za-z0-9]\", \"\")).filter(length($\"col\")>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_term = 1688528\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "1688528"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val num_term = df_term.distinct.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.Determine the most frequently occurring page title term in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_term_new = [col: string, count: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[col: string, count: bigint]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_term_new = df_term.groupBy(\"col\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[of,194407]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_term_new.orderBy($\"count\".desc).first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
